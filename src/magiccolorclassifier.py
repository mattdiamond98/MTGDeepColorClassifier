# -*- coding: utf-8 -*-
"""MagicColorClassifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VpA0qsAti7Hjb8ebvcdro0fQRuYRAUl9
"""

import numpy as np
import pandas as pd

import torch
import torch.nn as nn
from torch.optim import Adam
from torch.utils.data import Dataset, DataLoader

import tqdm
import math
import json

import itertools

import datetime

from matplotlib import pyplot as plt

from sklearn.metrics import hamming_loss, jaccard_score
from sklearn.preprocessing import MultiLabelBinarizer

#!pip install transformers

from transformers import BertTokenizer, BertModel

"""# Data"""

train_data = json.load(open('/content/drive/MyDrive/Colab Notebooks/mtg_train_data.json'))
test_data = json.load(open('/content/drive/MyDrive/Colab Notebooks/mtg_test_data.json'))

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)

print(train_data[0].keys())

max_length = 0
longest_text = ''
longest_encoding = None
for card_data in train_data + test_data:
  encoding = tokenizer.encode(card_data['text'])
  length = len(encoding)
  if length > max_length:
    max_length = length
    longest_text = card_data['text']
    longest_encoding = encoding
print('Max length:', max_length)
print('Text:', longest_text)
print('Encoding:', longest_encoding)

def one_hot_encode(mapping, values):
  encoding = torch.zeros(len(mapping))
  for value in values:
    if value in mapping.keys():
      encoding[mapping[value]] = 1.0
  return encoding

def create_mapping(values):
  return {val: i for i, val in enumerate(sorted(values))}

example_mapping = create_mapping(['Goblin', 'Elf', 'Warrior', 'Soldier', 'Rogue'])
example_one_hot_encoding = one_hot_encode(example_mapping, ['Goblin', 'Rogue', 'Fighter'])
print(example_mapping, example_one_hot_encoding)

all_types = set()
all_subtypes = {}
all_supertypes = set()

for card_data in train_data:
  all_types.update(card_data['types'])
  all_supertypes.update(card_data['supertypes'])

  for subtype in card_data['subtypes']:
    if subtype not in all_subtypes.keys():
      all_subtypes[subtype] = 1
    else:
      all_subtypes[subtype] += 1

print('Total types:', len(all_types))
print('Total subtypes:', len(all_subtypes))
print('Total supertypes:', len(all_supertypes))

print('Types:', all_types)
print('Supertypes:', all_supertypes)

all_subtypes_min_10 = [subtype[0] for subtype in all_subtypes.items() if subtype[1] >= 10]
print('Subtypes (min 10 count):', all_subtypes_min_10)
print('Total subtypes (min 10 count):', len(all_subtypes_min_10))

type_mapping = create_mapping(all_types)
subtype_mapping = create_mapping(all_subtypes_min_10)
supertype_mapping = create_mapping(all_supertypes)
print(type_mapping, supertype_mapping)

class MTGDataset(Dataset):

  def __init__(self, raw_card_data, include_raw_data=False):
    self.raw_card_data = raw_card_data

    self.X_text = None
    self.X_data = None
    self.Y      = None
    self.masks  = None
    
    self.__parse_cards()
    self.include_raw_data = include_raw_data
  
  def __parse_cards(self):
    for card in self.raw_card_data:
      # Include card['name'] potentially for LSTM later
      power_toughness_cost = [card['convertedManaCost'], card['power'], card['toughness']]  # indices 0, 1, 2
      type_encoded = one_hot_encode(type_mapping, card['types'])                            # indices 3-9
      supertype_encoded = one_hot_encode(supertype_mapping, card['supertypes'])             # indices 10, 11
      subtype_encoded = one_hot_encode(subtype_mapping, card['subtypes'])                   # indices 12-135

      cf = lambda c: 1.0 if c in card['colors'] else 0.0 # color function
      color_encoded = [cf('W'), cf('U'), cf('B'), cf('R'), cf('G')]

      text_encoded = tokenizer.encode_plus(
          card_data['text'],
          add_special_tokens = True,
          max_length=146,  
          padding='max_length',
          return_attention_mask = True,
          return_tensors = 'pt'
      )

      text_tensor     = text_encoded['input_ids'] # dim (1, 146)
      attention_mask  = text_encoded['attention_mask']

      power_toughness_cost_encoded = torch.tensor(power_toughness_cost)

      data_tensor  = torch.hstack([power_toughness_cost_encoded, type_encoded, supertype_encoded, subtype_encoded]).unsqueeze(0) # dim (1, 136)
      color_tensor = torch.tensor(color_encoded).unsqueeze(0) # dim (1, 5)
      
      if self.X_text is None:
        self.X_text = text_tensor
        self.X_data = data_tensor
        self.Y      = color_tensor
        self.masks  = attention_mask
      else:
        self.X_text = torch.cat([self.X_text, text_tensor])                                                             
        self.X_data = torch.cat([self.X_data, data_tensor])
        self.Y      = torch.cat([self.Y, color_tensor])     
        self.masks  = torch.cat([self.masks, attention_mask])                                                             

  def __len__(self):
    return len(self.raw_card_data)

  def __getitem__(self, idx):
    """
    Returns: X_text, X_data, attention_mask, Y (corresponding to the embedded text input, the rest of the card data and the color)
    """
    if self.include_raw_data:
      return self.X_text[idx], self.X_data[idx], self.masks[idx], self.Y[idx], self.raw_card_data[idx]
    return self.X_text[idx], self.X_data[idx], self.masks[idx], self.Y[idx]

train_dataset = MTGDataset(train_data)
test_dataset  = MTGDataset(test_data)

"""# Model"""

print(f'GPU available: {torch.cuda.is_available()}')
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Hyperparameters
BATCH_SIZE = 64

DIM_TRANSFORMER_OUT = 768
DIM_DATA = 136
DIM_OUTPUT= 5

DIM_HIDDEN = 128

LEARNING_RATE = 1e-5
TRANSFORMER_LEARNING_RATE = 1e-6

EPOCHS = 75

GRAD_CLIP = 3.0

class MagicColorClassifier(nn.Module):
  def __init__(self, dropout=0.0):
    super(MagicColorClassifier, self).__init__()

    self.transformer_model = BertModel.from_pretrained('bert-base-uncased')

    self.classifier = nn.Sequential(
        nn.Dropout(dropout),
        nn.Linear(DIM_DATA + DIM_TRANSFORMER_OUT, DIM_HIDDEN),
        nn.ReLU(),
        nn.Linear(DIM_HIDDEN, DIM_OUTPUT),
        nn.Sigmoid()
    )

  def forward(self, X_text, X_data, attention_masks):
    transformer_out = self.transformer_model(X_text, attention_mask=attention_masks)['pooler_output']

    classifier_input = torch.cat([X_data, transformer_out], dim=1)
    output      = self.classifier(classifier_input)

    return output

model = MagicColorClassifier().to(device)

train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_data_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE)

loss_func = torch.nn.CrossEntropyLoss(reduction='sum')

optimizer = Adam([
    {"params": model.transformer_model.parameters(), "lr": TRANSFORMER_LEARNING_RATE},
    {"params": model.classifier.parameters()}
], lr=LEARNING_RATE)

performance_curves = {'loss_train': [], 'acc_train': [], 'loss_test': [], 'acc_test': []}

def save_model_and_curves():
  now = datetime.datetime.now()
  dt_string = now.strftime("%d_%m_%y-%H:%M")
  print("Saving model and curves", dt_string)
  torch.save(model.state_dict(), f'/content/drive/MyDrive/Colab Notebooks/mtg_color_classifier_{dt_string}.model')
  with open(f'/content/drive/MyDrive/Colab Notebooks/mtg_performance_curves_{dt_string}.json', 'w') as outfile:
    json.dump(performance_curves, outfile)

for epoch in range(EPOCHS):
  total_loss_train = 0.0
  total_loss_test  = 0.0
  total_acc_train  = 0.0
  total_acc_test   = 0.0
  
  for train_batch_text, train_batch_data, attention_masks, train_batch_label in tqdm.notebook.tqdm(train_data_loader): 
    train_batch_label = train_batch_label.to(device)
    output = model(train_batch_text.to(device), train_batch_data.to(device), attention_masks.to(device))

    loss = loss_func(output, train_batch_label)
    loss /= output.shape[0]
    total_loss_train += loss.item()
    

    acc = torch.all(torch.eq(torch.round(output), train_batch_label), dim=1)
    acc = acc.sum().item()
    total_acc_train += acc

    model.zero_grad()
    loss.backward()
    nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)
    optimizer.step()

  with torch.no_grad():
    for test_batch_text, test_batch_data, attention_masks, test_batch_label in tqdm.notebook.tqdm(test_data_loader):
      test_batch_label = test_batch_label.to(device)
      output = model(test_batch_text.to(device), test_batch_data.to(device), attention_masks.to(device))
      loss = loss_func(output, test_batch_label)
      total_loss_test += loss.item()

      acc = torch.all(torch.eq(torch.round(output), test_batch_label), dim=1)
      acc = acc.sum().item()
      total_acc_test += acc

  total_loss_train /= len(train_dataset)
  total_acc_train /= len(train_dataset)
  total_loss_test /= len(test_dataset)
  total_acc_test /= len(test_dataset)

  print(
      f'Epochs: {epoch + 1} | Train Loss: {total_loss_train : .4f} \
      | Train Accuracy: {total_acc_train : .4f} \
      | Val Loss: {total_loss_test : .4f} \
      | Val Accuracy: {total_acc_test : .4f}')
  
  performance_curves['loss_train'] += [total_loss_train]
  performance_curves['acc_train']  += [total_acc_train]
  performance_curves['loss_test']  += [total_loss_test]
  performance_curves['acc_test']   += [total_acc_test]

  if epoch > 0 and epoch % 25 == 0 and epoch != EPOCHS:
    save_model_and_curves()
save_model_and_curves()

Best_so_far = "02_12_21-16:43" # 30, 31 train/test acc

final_train_dataset = MTGDataset(train_data, include_raw_data=True)
final_test_dataset = MTGDataset(test_data, include_raw_data=True)

final_train_data_loader = DataLoader(final_train_dataset, batch_size=1)
final_test_data_loader = DataLoader(final_test_dataset, batch_size=1)

"""# Results Compilation"""

model = MagicColorClassifier()
model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/mtg_color_classifier_02_12_21-16:43.model'))

model = model.eval().to(device)

def color_sort(colors):
  if len(colors) < 2:
    return colors
  return sorted(colors, key=lambda c: ['W', 'U', 'B', 'R', 'G'].index(c))

def output_to_list(output): # output is a tensor(5)
  output = torch.round(output)
  output = output.squeeze(0).tolist()
  output = [bool(o) for o in output]
  col_list = []
  for i, c in enumerate(['W', 'U', 'B', 'R', 'G']):
    if output[i]:
      col_list += [c]
  return col_list

def final_output(data_loader, model):
  final_output_list = []

  total_acc = 0

  with torch.no_grad():
      for test_batch_text, test_batch_data, attention_masks, test_batch_label, raw_data in tqdm.notebook.tqdm(data_loader):
        test_batch_label = test_batch_label.to(device)
        output = model(test_batch_text.to(device), test_batch_data.to(device), attention_masks.to(device))
        #loss = loss_func(output, test_batch_label)
        #total_loss_test += loss.item()
        predicted_colors = output_to_list(output)

        acc = torch.all(torch.eq(torch.round(output).squeeze(0), test_batch_label)).item()
        correct = bool(acc)

        final_output_list += [{
          'correct': correct,
          'colors': color_sort([col[0] for col in raw_data['colors']]),
          'predicted_colors': color_sort(predicted_colors),
          'name': raw_data['name'][0],
          'convertedManaCost': raw_data['convertedManaCost'][0].item(),
          'power': raw_data['power'][0].item(),
          'toughness': raw_data['toughness'][0].item(),
          'type': raw_data['type'][0],
          'text': raw_data['text'][0],
          'types': [t[0] for t in raw_data['types']],
          'supertypes': [t[0] for t in raw_data['supertypes']],
          'subtypes': [t[0] for t in raw_data['subtypes']]
        }]
        total_acc += acc
  results_df = pd.DataFrame(final_output_list)
  results_df.set_index('name')

  return total_acc / len(data_loader), results_df

total_acc_train, train_results_df = final_output(final_train_data_loader, model)
total_acc_test, test_results_df   = final_output(final_test_data_loader, model)

print(f'Total accuracy train: {total_acc_train: .4f}')
print(f'Total accuracy test: {total_acc_test: .4f}')

train_results_df

test_results_df

train_results_df.to_pickle('/content/drive/MyDrive/Colab Notebooks/train_results_df.pkl')
test_results_df.to_pickle('/content/drive/MyDrive/Colab Notebooks/test_results_df.pkl')

"""# Analysis"""

train_results_df = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/train_results_df.pkl')
test_results_df = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/test_results_df.pkl')

color_pie = ['W', 'U', 'B', 'R', 'G']
combinations = []
for L in range(0, len(color_pie)+1):
    for subset in itertools.combinations(color_pie, L):
        combinations += [subset]
print(combinations)

def gen_confusion_matrix(df, normalize=False):
  confusion_matrix = np.zeros((len(combinations), len(combinations)))
  for index, row in df.iterrows():
    confusion_matrix[combinations.index(tuple(row.colors)), combinations.index(tuple(row.predicted_colors))] += 1 
  if normalize:
    confusion_matrix = (confusion_matrix.T / confusion_matrix.sum(axis=1)).T
  return confusion_matrix

train_conf_matrix = gen_confusion_matrix(train_results_df, normalize=True)
test_conf_matrix = gen_confusion_matrix(test_results_df, normalize=True) # rows (y) is the true color, cols (x) is the predicted color

def col_text(color_tuple):
  if len(color_tuple) == 0:
    return 'C'
  return ''.join(color_tuple)

def show_conf_matrix(conf_matrix, labels, title):
  fig, ax = plt.subplots(figsize=(14, 14))
  ax.matshow(conf_matrix)

  for (i, j), z in np.ndenumerate(conf_matrix):
      ax.text(j, i, '{:0.2f}'.format(z), ha='center', va='center',
              bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))
  ax.set_xticks(range(len(labels)))
  ax.set_xticklabels([col_text(c) for c in labels])
  ax.set_yticks(range(len(labels)))
  ax.set_yticklabels([col_text(c) for c in labels])

  ax.set_xlabel('Predicted Label')
  ax.set_ylabel('True Label')
  ax.xaxis.set_label_position('top') 

  plt.title(title)

  plt.show()

show_conf_matrix(train_conf_matrix[:16, :16], combinations[:16], 'Train Confusion Matrix')

show_conf_matrix(test_conf_matrix[:16, :16], combinations[:16], 'Eval Confusion Matrix')

def accuracy_by_group(df_train, df_test, label, truncate_n=None):
  if truncate_n is not None:
    n_train, n_test = truncate_n
    #print(df.explode(label).groupby(label).filter(lambda l: truncate_n is None or len(l) > truncate_n)['correct'])
    group_count_train = df_train.explode(label).groupby(label).filter(lambda l: truncate_n is None or len(l) > n_train).groupby(label)['correct']
    group_count_test = df_test.explode(label).groupby(label).filter(lambda l: truncate_n is None or len(l) > n_test).groupby(label)['correct']
  else:
    group_count_train = df_train.explode(label).groupby(label)['correct']
    group_count_test = df_test.explode(label).groupby(label)['correct']

  return pd.DataFrame({
      "accuracy_train": group_count_train.sum() / group_count_train.count(), 
      "count_train": pd.to_numeric(group_count_train.count(), downcast='integer'), 
      "accuracy_test": group_count_test.sum() / group_count_test.count(), 
      "count_test": pd.to_numeric(group_count_test.count(), downcast='integer')
      }).dropna()

accuracy_by_group(train_results_df, test_results_df, 'types')

accuracy_by_group(train_results_df, test_results_df, 'supertypes')

accuracy_by_group(train_results_df, test_results_df, 'subtypes', truncate_n=(100, 20))

accuracy_by_group(train_results_df, test_results_df, 'convertedManaCost')

accuracy_by_group(train_results_df, test_results_df, 'colors')

def hamming_loss_func(df):
  mlb = MultiLabelBinarizer(classes=['W', 'U', 'B', 'R', 'G'])
  y_true = mlb.fit_transform(df['colors'].tolist())
  y_pred = mlb.fit_transform(df['predicted_colors'].tolist())
  return hamming_loss(y_true, y_pred)

def jaccard_score_func(df):
  mlb = MultiLabelBinarizer(classes=['W', 'U', 'B', 'R', 'G'])
  y_true = mlb.fit_transform(df['colors'].tolist())
  y_pred = mlb.fit_transform(df['predicted_colors'].tolist())
  return jaccard_score(y_true, y_pred, average='weighted')

hamming_loss_train = hamming_loss_func(train_results_df)
hamming_loss_test = hamming_loss_func(test_results_df)
print('train hamming loss:', hamming_loss_train, 'test hamming loss:', hamming_loss_test)

jaccard_score_train = jaccard_score_func(train_results_df)
jaccard_score_test = jaccard_score_func(test_results_df)
print('train jaccard_score:', jaccard_score_train, 'test jaccard_score:', jaccard_score_test)